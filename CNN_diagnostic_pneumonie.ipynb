{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804cb3b3",
   "metadata": {},
   "source": [
    "![CAT_DOG](img/banni√®re.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9468f",
   "metadata": {},
   "source": [
    "# üìå Contexte du projet\n",
    "\n",
    "Une √©quipe m√©dicale souhaite explorer l'apport de l'intelligence artificielle dans le diagnostic automatis√© de la **pneumonie** √† partir de **radios thoraciques**.\n",
    "\n",
    "üéØ Objectif :\n",
    "D√©velopper un **prototype fonctionnel (Proof of Concept)** capable de **classer automatiquement** une image en :\n",
    "- Pneumonie\n",
    "- Pas de pneumonie\n",
    "\n",
    "Le syst√®me repose sur la **r√©utilisation d‚Äôun mod√®le pr√©-entra√Æn√©** de type CNN (r√©duction du co√ªt d‚Äôentra√Ænement).  \n",
    "Le mod√®le choisi est **DenseNet121**, avec les **poids CheXNet** (entra√Æn√©s sur le jeu de donn√©es ChestX-ray14), adapt√©s √† la classification m√©dicale.\n",
    "\n",
    "üõ†Ô∏è Suivi des exp√©riences :  \n",
    "Le projet int√®gre **MLflow** pour le suivi des essais, la tra√ßabilit√© des mod√®les et les performances dans une logique **MLOps**.\n",
    "\n",
    "\n",
    "\n",
    "- mod√®le √† utiliser: CheXNet (ou le r√©seau de neuronne qui √† permis de le faire : Densenet121)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8e632",
   "metadata": {},
   "source": [
    "## üì¶ 1. Chargement des biblioth√®ques n√©cessaires\n",
    "\n",
    "Dans cette section, nous importons toutes les biblioth√®ques utiles pour :\n",
    "\n",
    "- la gestion des donn√©es et des images (`numpy`,`matplotlib`, etc.),\n",
    "- la construction et le chargement du mod√®le (`keras`),\n",
    "- le suivi des exp√©rimentations avec `MLflow`.\n",
    "\n",
    "Nous utilisons `TensorFlow/Keras` comme framework principal pour l'entra√Ænement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "#librairie tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#librairie mlflow\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "np.set_printoptions(edgeitems=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PIXEL = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            print(f\"Nom du GPU d√©tect√© : {gpu.name}\")\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} GPU(s) physique(s), {len(logical_gpus)} GPU(s) logique(s)\")\n",
    "        \n",
    "        # Afficher les infos depuis le runtime TensorFlow\n",
    "        from tensorflow.python.client import device_lib\n",
    "        devices = device_lib.list_local_devices()\n",
    "        for device in devices:\n",
    "            if device.device_type == 'GPU':\n",
    "                print(\"Nom      :\", device.name)\n",
    "                print(\"Type     :\", device.device_type)\n",
    "                print(\"M√©moire  :\", round(device.memory_limit / (1024**3), 2), \"GB\")\n",
    "                print(\"---------\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Aucun GPU d√©tect√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e444966",
   "metadata": {},
   "source": [
    "## üîç 2. Exploration des donn√©es\n",
    "\n",
    "Nous examinons la structure du jeu de donn√©es en visualisant les classes pr√©sentes (ex: `PNEUMONIA`, `NORMAL`) et quelques exemples d‚Äôimages.\n",
    "\n",
    "Cela permet de v√©rifier que les donn√©es sont bien organis√©es et de se faire une id√©e de leur contenu avant le pr√©traitement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/train\"\n",
    "\n",
    "classes = os.listdir(data_dir)\n",
    "print(\"Classes disponibles :\", classes)\n",
    "\n",
    "for label in classes:\n",
    "    path = os.path.join(data_dir, label)\n",
    "    sample_img = random.choice(os.listdir(path))\n",
    "    img = cv2.imread(os.path.join(path, sample_img), cv2.IMREAD_COLOR_RGB) #IMREAD_COLOR_RGB\n",
    "    print(f\"Classe : {label}\")\n",
    "    print(f\"Type des valeurs : {img.dtype}\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    # Inspection des m√©tadonn√©es de l'image\n",
    "    print(f\"Shape (dimensions)    : {img.shape}\")\n",
    "    print(f\"Type des valeurs      : {img.dtype}\")\n",
    "    plt.show()\n",
    "    # Observer l'image sous forme de matrice\n",
    "    #print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca81afe",
   "metadata": {},
   "source": [
    "## üßπ 3. Pr√©paration des donn√©es\n",
    "\n",
    "Nous utilisons un g√©n√©rateur de donn√©es (`ImageDataGenerator`) pour :\n",
    "\n",
    "- redimensionner les images √† la taille attendue par le mod√®le (224x224),\n",
    "- effectuer une normalisation simple (rescale),\n",
    "- cr√©er un split automatique entre **donn√©es d'entra√Ænement** et **donn√©es de validation** (20%).\n",
    "\n",
    "Les images sont converties en **RGB**, car le mod√®le pr√©entra√Æn√© attend 3 canaux d‚Äôentr√©e.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dbf0e",
   "metadata": {},
   "source": [
    "## üß™ 4. Preprocessing\n",
    "\n",
    "Le pr√©traitement est effectu√© automatiquement par `ImageDataGenerator`, avec les √©tapes suivantes :\n",
    "\n",
    "- redimensionnement des images (224x224),\n",
    "- conversion en 3 canaux (RGB),\n",
    "- effectuer une normalisation simple (rescale)\n",
    "- normalisation des pixels (entre 0 et 1).\n",
    "\n",
    "Les images sont converties en **RGB**, car le mod√®le pr√©entra√Æn√© attend 3 canaux d‚Äôentr√©e.\n",
    "Ces transformations sont n√©cessaires pour que les images soient compatibles avec le mod√®le DenseNet121.\n",
    "\n",
    "Ces modifications sont faites pour les 3 dataset qui sont:\n",
    "- test\n",
    "- train\n",
    "- val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trier les images valides des images corrompues\n",
    "# def get_valid_images(directory):\n",
    "#     valid_images = []\n",
    "#     labels = []\n",
    "\n",
    "#     # Parcours des sous-dossiers (classes)\n",
    "#     for class_name in os.listdir(directory):\n",
    "#         class_dir = os.path.join(directory, class_name)\n",
    "#         if not os.path.isdir(class_dir):\n",
    "#             continue\n",
    "\n",
    "#         for fname in os.listdir(class_dir):\n",
    "#             fpath = os.path.join(class_dir, fname)\n",
    "#             try:\n",
    "#                 with Image.open(fpath) as img:\n",
    "#                     img.verify()  # V√©rifie sans charger en m√©moire\n",
    "#                 valid_images.append(fpath)\n",
    "#                 labels.append(class_name)\n",
    "#             except:\n",
    "#                 print(f\"Image corrompue ignor√©e : {fpath}\")\n",
    "\n",
    "#     return pd.DataFrame({'filename': valid_images, 'class': labels})\n",
    "\n",
    "# # === Chemin vers ton dataset\n",
    "# test_dir = 'data/train'\n",
    "# train_dir = 'data/test'\n",
    "# val_dir = 'data/val'\n",
    "\n",
    "# # === Liste des images valides\n",
    "# df_test = get_valid_images(test_dir)\n",
    "# df_train = get_valid_images(train_dir)\n",
    "# df_val = get_valid_images(val_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Pr√©traitement commun\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# G√©n√©rateur pour l'entra√Ænement\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# G√©n√©rateur pour le test final\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# G√©n√©rateur pour la validation\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'data/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #transformer les label en int\n",
    "# label_to_int = {\"NORMAL\": 0, \"PNEUMONIA\": 1}\n",
    "\n",
    "# def get_train_test(base_path: str, target_size=(IMAGE_PIXEL)):\n",
    "#     X = []  # liste pour stocker les images\n",
    "#     y = []  # liste pour stocker les √©tiquettes correspondantes\n",
    "\n",
    "#     # On parcourt les sous-dossiers du r√©pertoire (un dossier par chiffre)\n",
    "#     for label in sorted(os.listdir(base_path)):\n",
    "#         # on ignore les fichiers qui ne sont pas des dossiers de chiffres\n",
    "#         # if not label.isdigit():\n",
    "#         #     continue\n",
    "#         label_path = os.path.join(base_path, label)\n",
    "\n",
    "#         # On parcourt chaque image du dossier\n",
    "#         for file_name in os.listdir(label_path):\n",
    "#             file_path = os.path.join(label_path, file_name)\n",
    "#             # Lecture de l'image en niveaux de gris\n",
    "#             img = cv2.imread(file_path, cv2.IMREAD_COLOR_RGB)\n",
    "#             if img is None:\n",
    "#                 continue  # image illisible, on passe\n",
    "            \n",
    "#             img_resized = cv2.resize(img, target_size)\n",
    "#             X.append(img_resized)           # on ajoute l'image √† la liste\n",
    "#             y.append(int(label_to_int[label]))    # on ajoute le label (ex: 0, 1, ..., 9)\n",
    "\n",
    "#     # Conversion des listes en tableaux NumPy\n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)\n",
    "#     return X, y\n",
    "\n",
    "# X_train, y_train = get_train_test(\"data/train\")\n",
    "# X_test, y_test = get_train_test(\"data/test\")\n",
    "# X_val, y_val = get_train_test(\"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd496d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Les images sont au format (28, 28). On les convertit en float pour normaliser ensuite\n",
    "# X_train = X_train.astype(\"float32\")\n",
    "# X_test = X_test.astype(\"float32\")\n",
    "# X_val = X_test.astype(\"float32\")\n",
    "\n",
    "# # Normalisation : on divise les valeurs de pixels par 255 pour les ramener entre 0 et 1\n",
    "# X_train /= 255.0\n",
    "# X_test /= 255.0\n",
    "# X_val /= 255.0\n",
    "\n",
    "# # Flatten : pour un MLP, chaque image 28x28 doit devenir un vecteur de 784 valeurs\n",
    "# #X_train = X_train.reshape(X_train.shape[0], 64 * 64)\n",
    "# #X_test = X_test.reshape(X_test.shape[0], 64 * 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48bc54",
   "metadata": {},
   "source": [
    "## üß† 5. Mod√©lisation\n",
    "\n",
    "Nous utilisons le mod√®le **DenseNet121** disponible dans `Keras`, sans ses poids par d√©faut (`weights=None`), et nous le compl√©tons avec une couche de classification binaire.\n",
    "\n",
    "Ensuite, nous **chargeons les poids pr√©entra√Æn√©s de CheXNet**, disponibles au format `.h5`.  \n",
    "Ces poids proviennent d‚Äôun entra√Ænement sur un grand jeu de radios thoraciques (ChestX-ray14), et permettent d‚Äôadapter DenseNet121 au domaine m√©dical.\n",
    "\n",
    "Le mod√®le final est compil√© pour une t√¢che de classification binaire (pneumonie vs normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b8d14",
   "metadata": {},
   "source": [
    "## cr√©ation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f69a0f",
   "metadata": {},
   "source": [
    "on reconstruit le m√™me modele que cheXnet (pour charger les poids) car:\n",
    "- Les poids .h5 sont associ√©s √† une architecture exacte\n",
    "- on dois d‚Äôabord reconstruire cette m√™me architecture (14 classes) pour les charger\n",
    "- Puis, on peux couper/remplacer la derni√®re couche pour ton cas d‚Äôusage (binaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod√®le bas√© sur DenseNet121\n",
    "input_tensor = layers.Input(shape=(IMAGE_PIXEL[0], IMAGE_PIXEL[1], 3))\n",
    "model_densenet121 = DenseNet121(include_top=False, weights=None, input_tensor=input_tensor)\n",
    "\n",
    "x = model_densenet121.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "output = layers.Dense(14, activation='sigmoid')(x)  # 14 sorties comme CheXNet\n",
    "\n",
    "#output = layers.Dense(1, activation='sigmoid')(x)  # Binaire : pneumonie ou non\n",
    "\n",
    "\n",
    "model = models.Model(inputs= model_densenet121.input, outputs=output)\n",
    "\n",
    "# Charger les poids de CheXNet (Keras)\n",
    "model.load_weights(\"weights/CheXNet_Keras_0.3.0_weights.h5\")\n",
    "\n",
    "# Retirer la derni√®re couche et en ajouter une nouvelle\n",
    "x = model.layers[-2].output  # on reprend la couche GlobalAveragePooling2D\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = models.Model(inputs=model.input, outputs=output)\n",
    "\n",
    "# Freeze toutes les couches du mod√®le (sauf la nouvelle couche Dense)\n",
    "for layer in model.layers[:-1]:  # G√®le tout sauf la derni√®re\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler\n",
    "model.compile(\n",
    "    optimizer='adam',                            # M√©thode d‚Äôoptimisation (descente de gradient)\n",
    "    loss='binary_crossentropy',                  # Fonction de perte pour classification multi-classe avec √©tiquettes enti√®res (ex : 0 √† 9)\n",
    "    metrics=['accuracy'])                        # On surveille l‚Äôexactitude pendant l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© du mod√®le\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf934cf3",
   "metadata": {},
   "source": [
    "## üìà 6. √âvaluation du mod√®le & Suivi avec MLflow\n",
    "\n",
    "Nous entra√Ænons le mod√®le sur les radios et √©valuons ses performances sur l'ensemble de validation.\n",
    "\n",
    "Dans une logique de **tra√ßabilit√© exp√©rimentale**, nous utilisons **MLflow** pour :\n",
    "\n",
    "- enregistrer automatiquement les m√©triques d'entra√Ænement (loss, accuracy, etc.),\n",
    "- suivre les param√®tres du mod√®le,\n",
    "- sauvegarder l'historique des essais pour une future comparaison ou mise en production.\n",
    "\n",
    "Ceci initie une approche MLOps pour le suivi reproductible de nos exp√©riences.\n",
    "\n",
    "- lancer mlflow: mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"CheXNet - Pneumonia Detection\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)       # √©viter le surapprentissage\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. D√©figer certaines couches + recompiler\n",
    "for layer in model.layers[-11:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# ‚ö†Ô∏è Recompiler apr√®s avoir modifi√© trainable\n",
    "model.compile(optimizer=optimizers.Adam(1e-5),  # ‚Üê plus petit LR pour ne pas d√©truire les poids\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Deuxi√®me phase d'entra√Ænement (fine-tuning)\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_generator)\n",
    "print(f\"Accuracy sur le test : {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nommage = {0:\"NORMAL\", 1:\"PNEUMONIA\"}\n",
    "\n",
    "# === Nombre total d'images dans le test_generator\n",
    "n_images = test_generator.samples\n",
    "\n",
    "# === Tirer un indice al√©atoire entre 0 et n_images - 1\n",
    "index = random.randint(0, n_images - 1)\n",
    "\n",
    "# === Calculer le batch et la position dans le batch\n",
    "batch_size = test_generator.batch_size\n",
    "batch_index = index // batch_size\n",
    "image_index = index % batch_size\n",
    "\n",
    "# === Charger le batch correspondant\n",
    "images_batch, labels_batch = test_generator[batch_index]\n",
    "\n",
    "# === R√©cup√©rer l‚Äôimage et le label √† cet index\n",
    "img = images_batch[image_index]\n",
    "label = labels_batch[image_index]\n",
    "\n",
    "# === Montrer l‚Äôimage avec le label\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label attendu : {nommage[label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# === Pr√©diction\n",
    "img_input = np.expand_dims(img, axis=0)\n",
    "pred = model.predict(img_input)\n",
    "\n",
    "# === Interpr√©tation\n",
    "display(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (monenv)",
   "language": "python",
   "name": "monenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
