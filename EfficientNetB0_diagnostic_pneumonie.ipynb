{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804cb3b3",
   "metadata": {},
   "source": [
    "![CAT_DOG](img/banni√®re.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9468f",
   "metadata": {},
   "source": [
    "# üìå Contexte du projet\n",
    "\n",
    "Une √©quipe m√©dicale souhaite explorer l'apport de l'intelligence artificielle dans le diagnostic automatis√© de la **pneumonie** √† partir de **radios thoraciques**.\n",
    "\n",
    "üéØ Objectif :\n",
    "D√©velopper un **prototype fonctionnel (Proof of Concept)** capable de **classer automatiquement** une image en :\n",
    "- Pneumonie\n",
    "- Pas de pneumonie\n",
    "\n",
    "Le syst√®me repose sur la **r√©utilisation d‚Äôun mod√®le pr√©-entra√Æn√©** de type CNN (r√©duction du co√ªt d‚Äôentra√Ænement).  \n",
    "Le mod√®le choisi est **DenseNet121**, avec les **poids CheXNet** (entra√Æn√©s sur le jeu de donn√©es ChestX-ray14), adapt√©s √† la classification m√©dicale.\n",
    "\n",
    "üõ†Ô∏è Suivi des exp√©riences :  \n",
    "Le projet int√®gre **MLflow** pour le suivi des essais, la tra√ßabilit√© des mod√®les et les performances dans une logique **MLOps**.\n",
    "\n",
    "\n",
    "\n",
    "- mod√®le √† utiliser: CheXNet (ou le r√©seau de neuronne qui √† permis de le faire : Densenet121)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8e632",
   "metadata": {},
   "source": [
    "## üì¶ 1. Chargement des biblioth√®ques n√©cessaires\n",
    "\n",
    "Cette section pr√©pare l‚Äôenvironnement pour :\n",
    "\n",
    "- la gestion des donn√©es et des images (`numpy`, `matplotlib`, etc.),\n",
    "- l‚Äôinteraction avec MLflow via `mlflow.keras` et `MlflowClient`,\n",
    "- le chargement dynamique du **dernier mod√®le versionn√©** depuis le **Model Registry MLflow**.\n",
    "\n",
    "Nous utilisons `TensorFlow/Keras` comme framework principal, et MLflow pour le suivi et le chargement du mod√®le.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fc4a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:40:14.750295: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748097614.764563   32053 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748097614.769026   32053 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748097614.779336   32053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748097614.779359   32053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748097614.779360   32053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748097614.779361   32053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-24 16:40:14.783326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "from datetime import datetime\n",
    "from time import strftime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "#os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=off'\n",
    "\n",
    "#librairie tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#librairie mlflow\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.data import Dataset\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.keras\n",
    "\n",
    "\n",
    "IMAGE_PIXEL = (224, 224)\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "np.set_printoptions(edgeitems=30) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1e8b0",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è V√©rification utilisation carte graphique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            print(f\"Nom du GPU d√©tect√© : {gpu.name}\")\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} GPU(s) physique(s), {len(logical_gpus)} GPU(s) logique(s)\")\n",
    "      \n",
    "        # Afficher les infos depuis le runtime TensorFlow\n",
    "        from tensorflow.python.client import device_lib\n",
    "        devices = device_lib.list_local_devices()\n",
    "        for device in devices:\n",
    "            if device.device_type == 'GPU':\n",
    "                print(\"Nom      :\", device.name)\n",
    "                print(\"Type     :\", device.device_type)\n",
    "                print(\"M√©moire  :\", round(device.memory_limit / (1024**3), 2), \"GB\")\n",
    "                print(\"---------\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Aucun GPU d√©tect√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e444966",
   "metadata": {},
   "source": [
    "## üîç 2. Exploration des donn√©es\n",
    "\n",
    "Nous examinons ici la structure du jeu de donn√©es pour comprendre les classes disponibles (`PNEUMONIA`, `NORMAL`) et visualiser quelques exemples d‚Äôimages.\n",
    "\n",
    "Cette √©tape permet de :\n",
    "- v√©rifier que les donn√©es sont bien organis√©es,\n",
    "- anticiper les besoins de pr√©traitement,\n",
    "- s'assurer que le jeu de donn√©es est coh√©rent avant d'utiliser un mod√®le pr√©entra√Æn√©.\n",
    "\n",
    "Elle est essentielle pour garantir que les images soient compatibles avec le mod√®le DenseNet121 utilis√© plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/train\"\n",
    "\n",
    "classes = os.listdir(data_dir)\n",
    "print(\"Classes disponibles :\", classes)\n",
    "\n",
    "for label in classes:\n",
    "    path = os.path.join(data_dir, label)\n",
    "    sample_img = random.choice(os.listdir(path))\n",
    "    img = cv2.imread(os.path.join(path, sample_img), cv2.IMREAD_COLOR_RGB) #IMREAD_COLOR_RGB\n",
    "    print(f\"Classe : {label}\")\n",
    "    print(f\"Type des valeurs : {img.dtype}\")\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    # Inspection des m√©tadonn√©es de l'image\n",
    "    print(f\"Shape (dimensions)    : {img.shape}\")\n",
    "    print(f\"Type des valeurs      : {img.dtype}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dbf0e",
   "metadata": {},
   "source": [
    "## üß™ 3. Pr√©traitement des donn√©es\n",
    "\n",
    "Nous pr√©parons les images √† √™tre directement consomm√©es par le mod√®le DenseNet121 :\n",
    "\n",
    "- redimensionnement √† 224x224 pixels,\n",
    "- conversion en RGB (3 canaux),\n",
    "- mise √† l‚Äô√©chelle des pixels (valeurs entre 0 et 1).\n",
    "\n",
    "Ces transformations sont r√©alis√©es automatiquement avec `ImageDataGenerator` pour les ensembles :\n",
    "- `train`\n",
    "- `validation`\n",
    "- `test`\n",
    "\n",
    "Ce pr√©traitement est crucial pour garantir que les donn√©es correspondent aux attentes du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©traitement commun\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# G√©n√©rateur pour l'entra√Ænement\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(IMAGE_PIXEL[0], IMAGE_PIXEL[1]),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# G√©n√©rateur pour le test final\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(IMAGE_PIXEL[0], IMAGE_PIXEL[1]),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# G√©n√©rateur pour la validation\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'data/val',\n",
    "    target_size=(IMAGE_PIXEL[0], IMAGE_PIXEL[1]),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48bc54",
   "metadata": {},
   "source": [
    "## üß† 4. Mod√©lisation et suivi avec MLflow\n",
    "\n",
    "Nous utilisons ici le mod√®le **DenseNet121** de `Keras` comme base, sans ses poids par d√©faut (`weights=None`), afin de le personnaliser pour notre cas d‚Äôusage.\n",
    "\n",
    "### √âtapes de mod√©lisation :\n",
    "\n",
    "1. **Reconstruction fid√®le de l'architecture CheXNet** :  \n",
    "   Pour pouvoir charger les poids `.h5` pr√©entra√Æn√©s, nous devons recr√©er exactement la structure d‚Äôorigine du mod√®le CheXNet (14 classes en sortie).\n",
    "\n",
    "2. **Chargement des poids CheXNet** :  \n",
    "   Ces poids sont issus d‚Äôun entra√Ænement sur le jeu de donn√©es **ChestX-ray14**, et permettent au mod√®le de b√©n√©ficier d‚Äôune bonne repr√©sentation des pathologies pulmonaires d√®s le d√©part.\n",
    "\n",
    "3. **Adaptation pour notre t√¢che** :  \n",
    "   Une fois les poids charg√©s, nous supprimons la couche de sortie d‚Äôorigine (14 classes) et la rempla√ßons par une couche adapt√©e √† notre besoin de **classification binaire** : `PNEUMONIA` vs `NORMAL`.\n",
    "\n",
    "4. **Compilation du mod√®le** :  \n",
    "   Le mod√®le est compil√© pour une t√¢che de classification binaire avec une fonction de perte adapt√©e (`binary_crossentropy`), un optimiseur (ex. Adam) et des m√©triques pertinentes (accuracy, precision, etc.).\n",
    "\n",
    "### Suivi avec MLflow\n",
    "\n",
    "Nous utilisons **MLflow** pour suivre chaque exp√©rimentation de mani√®re rigoureuse :\n",
    "\n",
    "- journalisation automatique des m√©triques d'entra√Ænement (loss, accuracy, etc.),\n",
    "- enregistrement des hyperparam√®tres et de la structure du mod√®le,\n",
    "- sauvegarde du mod√®le entra√Æn√© pour une r√©utilisation future ou comparaison.\n",
    "\n",
    "üí° Pour visualiser les essais dans l'interface MLflow :\n",
    "```bash\n",
    "mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5386e",
   "metadata": {},
   "source": [
    "#### cr√©ation de params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90018c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    \"run_name\": f\"EfficientNetB0-transfer { datetime.now().strftime('%Y-%m-%d %H:%M:%S') }\",\n",
    "    \"description\": \"test du modele DenseNet121 avec les poids du modele CheXpert\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"base_model\": \"EfficientNetB0\",     # Nom du mod√®le de base pr√©-entra√Æn√© utilis√©\n",
    "    \"frozen_epochs\": 10,              # Nombre d‚Äô√©poques pour la phase 1 (entra√Ænement du \"head\" avec le backbone gel√©)\n",
    "    \"finetune_epochs\": 10,            # Nombre d‚Äô√©poques pour la phase 2 (fine-tuning avec le backbone partiellement ou totalement d√©gel√©)\n",
    "    \"lr_frozen\": 1e-3,               # Learning rate (taux d‚Äôapprentissage) pour la phase 1\n",
    "    \"lr_finetune\": 1e-5              # Learning rate pour la phase 2 (souvent plus bas pour √©viter de d√©truire les poids pr√©-entra√Æn√©s)\n",
    "}\n",
    "\n",
    "tags = {\n",
    "    \"framework\": \"Keras\",\n",
    "    \"model_type\": \"CNN\",\n",
    "    \"model\": \"EfficientNetB0\",\n",
    "    \"mlflow.dataset.name\": \"pneumonia_kaggle\",\n",
    "    \"mlflow.dataset.context\": \"training\",\n",
    "    \"mlflow.dataset.source_type\": \"url\",\n",
    "    \"mlflow.dataset.source\": \"https://www.kaggle.com/datasets/nom_du_dataset\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410aca7b",
   "metadata": {},
   "source": [
    "#### cr√©ation de fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarder toute les informations re√ßu dans les metrics de mlflow\n",
    "def save_log_history(history, prefix=\"\" ,metrics = [\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"]):\n",
    "    for i in range(len(history[\"loss\"])):\n",
    "        for metric in metrics:\n",
    "            if metric in history:\n",
    "                mlflow.log_metric(f\"{prefix}_{metric}\", history[metric][i], step= i)\n",
    "\n",
    "\n",
    "#sauvegarder les graphs des performances dans mlflow             \n",
    "def draw_graph(list_val, metric, epochs):\n",
    "    epochs_frozen = list(range(1, len(list_val['frozen']) + 1))\n",
    "    epochs_unfrozen = list(range(1, len(list_val['unfrozen']) + 1))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(epochs_frozen, list_val['frozen'], label=f'Frozen {metric}', color='blue')\n",
    "    ax.plot(epochs_unfrozen, list_val['unfrozen'], label=f'Unfrozen {metric}', color='orange')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(f'{metric}')\n",
    "    ax.set_title(f'Training {metric} per Phase')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "        \n",
    "    mlflow.log_figure(fig, f\"{metric}_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13b189",
   "metadata": {},
   "source": [
    "#### cr√©ation modele + utilisation de mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Pneumonia Detection\")\n",
    "mlflow.keras.autolog(disable=True) # desactivation du log automatique\n",
    "with mlflow.start_run(**run_params):\n",
    "    \n",
    "    #ajouter des info dans mlflow\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.log_params(params)\n",
    "        \n",
    "    #mlflow.log_input(dataset, context=\"training\")\n",
    "    \n",
    "    # Mod√®le bas√© sur DenseNet121\n",
    "    input_tensor = layers.Input(shape=(IMAGE_PIXEL[0], IMAGE_PIXEL[1], 3))\n",
    "    \n",
    "    #utilisation du modele DenseNet (cr√©ation sans poids afin de rajouter ceux de CheXNet)\n",
    "    model_efficientNetb0 = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "    x = model_efficientNetb0.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)   # Retirer la derni√®re couche et en ajouter une nouvelle\n",
    "    model = models.Model(inputs=model_efficientNetb0.input, outputs=output)\n",
    "\n",
    "    for layer in model.layers[:-1]:  # Freeze toutes les couches du mod√®le (sauf la nouvelle couche Dense)\n",
    "        layer.trainable = False\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)       # √©viter le surapprentissage\n",
    "        \n",
    "    # Compiler\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(params['lr_frozen']),          # M√©thode d‚Äôoptimisation (descente de gradient)\n",
    "        loss='binary_crossentropy',                              # Fonction de perte pour classification multi-classe avec √©tiquettes enti√®res (ex : 0 √† 9)\n",
    "        metrics=['accuracy'])                                    # On surveille l‚Äôexactitude pendant l'entra√Ænement\n",
    "    \n",
    "    # print(\"Warmup...\")\n",
    "    # model.train_on_batch(train_generator)\n",
    "    # print(\"Warmup termin√© ‚úÖ\")\n",
    "    \n",
    "    history_frozen = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs= params['frozen_epochs'],\n",
    "    batch_size = 32,\n",
    "    callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    # Log manuel phase 1 (history_frozen)\n",
    "    save_log_history(history=history_frozen.history, prefix=\"frozen\")\n",
    "       \n",
    "    # D√©figer certaines couches + recompiler\n",
    "    for layer in model.layers[-11:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompiler apr√®s avoir modifi√© trainable\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(params['lr_finetune']),  #plus petit LR pour ne pas d√©truire les poids\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # print(\"Warmup...\")\n",
    "    # model.train_on_batch(train_generator)\n",
    "    # print(\"Warmup termin√© ‚úÖ\")\n",
    "\n",
    "    # Deuxi√®me phase d'entra√Ænement (fine-tuning)\n",
    "    history_unfrozen = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs= params['finetune_epochs'],\n",
    "        batch_size = 32,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    \n",
    "    # Log manuel phase 2 (history_unfrozen)\n",
    "    save_log_history(history=history_unfrozen.history, prefix=\"unfrozen\")\n",
    "\n",
    "    # tracer les graph\n",
    "    for metric in history_frozen.history:\n",
    "        draw_graph({\"frozen\": history_frozen.history[metric], \"unfrozen\": history_unfrozen.history[metric] }, metric, 10)\n",
    "    \n",
    "    \n",
    "    # √âvaluation finale\n",
    "    loss, acc = model.evaluate(test_generator)  \n",
    "    mlflow.log_metric(\"final_test_loss\", loss)\n",
    "    mlflow.log_metric(\"final_test_accuracy\", acc)\n",
    "    \n",
    "    # Exemple d'entr√©e : un batch al√©atoire\n",
    "    input_example = np.random.rand(1, IMAGE_PIXEL[0], IMAGE_PIXEL[1], 3).astype(np.float32)\n",
    "\n",
    "    # Pr√©diction pour obtenir un exemple de sortie\n",
    "    output_example = model.predict(input_example)\n",
    "\n",
    "    # D√©duire la signature\n",
    "    signature = infer_signature(input_example, output_example)\n",
    "    \n",
    "    # sauvegarde du modele\n",
    "    mlflow.keras.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"Pneumonia_EfficientNetB0_Model\",\n",
    "        signature= signature\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© complet du mod√®le\n",
    "#model.summary()\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf934cf3",
   "metadata": {},
   "source": [
    "## üìà 5. √âvaluation du mod√®le\n",
    "\n",
    "Nous proc√©dons √† l‚Äô√©valuation du mod√®le pr√©alablement entra√Æn√© en analysant ses performances sur le jeu de validation.\n",
    "\n",
    "### üîç M√©triques utilis√©es\n",
    "\n",
    "Pour obtenir une √©valuation compl√®te et fiable, nous utilisons plusieurs m√©triques compl√©mentaires :\n",
    "\n",
    "- **Accuracy** : proportion de pr√©dictions correctes sur l‚Äôensemble des √©chantillons.\n",
    "- **Precision** : capacit√© du mod√®le √† ne pas g√©n√©rer de faux positifs.\n",
    "- **Recall (Sensibilit√©)** : capacit√© du mod√®le √† d√©tecter les vrais positifs.\n",
    "- **F1-score** : compromis entre pr√©cision et rappel, particuli√®rement pertinent en cas de classes d√©s√©quilibr√©es.\n",
    "- **Matrice de confusion** : repr√©sentation visuelle des erreurs de classification pour chaque classe.\n",
    "\n",
    "Ces m√©triques ont √©t√© s√©lectionn√©es afin de refl√©ter la performance du mod√®le dans un contexte m√©dical, o√π les erreurs peuvent avoir des cons√©quences diff√©rentes selon leur nature (faux positifs vs faux n√©gatifs).\n",
    "\n",
    "### ‚úÖ Chargement et test du mod√®le\n",
    "\n",
    "Le mod√®le est recharg√© depuis **MLflow** afin d‚Äôassurer la coh√©rence de l‚Äô√©valuation avec la version sauvegard√©e lors de l'entra√Ænement. Cette √©tape permet de valider que le mod√®le stock√© est op√©rationnel et pr√™t √† √™tre compar√© ou d√©ploy√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819616b8",
   "metadata": {},
   "source": [
    "## matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ca586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1 : Pr√©dictions sur les donn√©es de test\n",
    "y_pred_proba = model.predict(test_generator)\n",
    "y_pred = (y_pred_proba > 0.5).astype(\"int\").flatten()\n",
    "\n",
    "# √âtape 2 : √âtiquettes vraies\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# √âtape 3 : Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Affichage avec seaborn\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=ax)\n",
    "ax.set_xlabel(\"Pr√©diction\")\n",
    "ax.set_ylabel(\"V√©rit√©\")\n",
    "ax.set_title(\"Matrice de confusion\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8cbe8",
   "metadata": {},
   "source": [
    "## scores obtenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision :\", precision_score(y_true, y_pred))\n",
    "print(\"Recall :\", recall_score(y_true, y_pred))\n",
    "print(\"F-score :\", f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32766a",
   "metadata": {},
   "source": [
    "valeur importante: **Recall**\n",
    "- mesure la capacit√© du modele √† detecter les vrais pneumonie\n",
    "- une pneumonie non detecter est plus grave que l'inverse (faux n√©gatif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b009d5",
   "metadata": {},
   "source": [
    "## test du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nommage = {0:\"NORMAL\", 1:\"PNEUMONIA\"}\n",
    "\n",
    "# # === Nombre total d'images dans le test_generator\n",
    "n_images = test_generator.samples\n",
    "\n",
    "# # === Tirer un indice al√©atoire entre 0 et n_images - 1\n",
    "index = random.randint(0, n_images - 1)\n",
    "\n",
    "# # === Calculer le batch et la position dans le batch\n",
    "batch_size = test_generator.batch_size\n",
    "batch_index = index // batch_size\n",
    "image_index = index % batch_size\n",
    "\n",
    "# # === Charger le batch correspondant\n",
    "images_batch, labels_batch = test_generator[batch_index]\n",
    "\n",
    "# # === R√©cup√©rer l‚Äôimage et le label √† cet index\n",
    "img = images_batch[image_index]\n",
    "label = labels_batch[image_index]\n",
    "\n",
    "# # === Montrer l‚Äôimage avec le label\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label attendu : {nommage[label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# # === Pr√©diction\n",
    "img_input = np.expand_dims(img, axis=0)\n",
    "pred = model.predict(img_input)\n",
    "\n",
    "# # === Interpr√©tation\n",
    "display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©e un client MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# R√©cup√®re toutes les versions du mod√®le\n",
    "all_versions = client.search_model_versions(\"name='Pneumonia_CheXNet_Model'\")\n",
    "\n",
    "# Trie par version (en int) pour obtenir la derni√®re\n",
    "latest_version_info = max(all_versions, key=lambda v: int(v.version))\n",
    "\n",
    "# Cr√©e l'URI du mod√®le\n",
    "model_uri = f\"models:/Pneumonia_CheXNet_Model/{latest_version_info.version}\"\n",
    "\n",
    "# Charge le mod√®le avec mlflow.keras\n",
    "model = mlflow.keras.load_model(model_uri)\n",
    "\n",
    "# # === Montrer l‚Äôimage avec le label\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label attendu : {nommage[label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# # === Pr√©diction\n",
    "img_input = np.expand_dims(img, axis=0)\n",
    "pred = model.predict(img_input)\n",
    "\n",
    "# # === Interpr√©tation\n",
    "display(pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nom_env)",
   "language": "python",
   "name": "nom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
